{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to extract the coordinates of the keypoints from the image and writing it to the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "'../data/amrit_basic.jpg',\n",
    " '../data/amrit_flex.jpg',\n",
    " '../data/amrit_leg_stretch.jpg',\n",
    " '../data/amrit_lunge.jpg',\n",
    " '../data/amrit_pray.jpg',\n",
    " '../data/amrit_squat.jpg',\n",
    " '../data/amrit_surya_four.jpg',\n",
    " '../data/amrit_surya_three.jpg',\n",
    " '../data/amrit_t_pose.jpg',\n",
    " '../data/amrit_zigzag.jpg',\n",
    " '../data/pavan_dance.jpg',\n",
    " '../data/pavan_flamingo.jpg',\n",
    " '../data/pavan_full_stop.jpg',\n",
    " '../data/pavan_jesus.jpg',\n",
    " '../data/pavan_karate_kick.jpg',\n",
    " '../data/pavan_left_stretch.jpg',\n",
    " '../data/pavan_neck_stretch.jpg',\n",
    " '../data/pavan_surya_two.jpg',\n",
    " '../data/pavan_t_pose_variant.jpg',\n",
    " '../data/pavan_wicketkeeper.jpg'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('../models/yolov8n-pose.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the Co-ordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 person, 40.6ms\n",
      "Speed: 7.4ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 40.1ms\n",
      "Speed: 3.5ms preprocess, 40.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 persons, 38.6ms\n",
      "Speed: 4.8ms preprocess, 38.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 persons, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 persons, 18.9ms\n",
      "Speed: 3.7ms preprocess, 18.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 persons, 21.0ms\n",
      "Speed: 4.7ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 19.8ms\n",
      "Speed: 3.5ms preprocess, 19.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 21.3ms\n",
      "Speed: 6.1ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 19.2ms\n",
      "Speed: 4.6ms preprocess, 19.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 22.5ms\n",
      "Speed: 2.3ms preprocess, 22.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 21.3ms\n",
      "Speed: 4.4ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 21.7ms\n",
      "Speed: 4.9ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 21.8ms\n",
      "Speed: 4.2ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 19.9ms\n",
      "Speed: 2.6ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 22.3ms\n",
      "Speed: 2.8ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 21.4ms\n",
      "Speed: 3.6ms preprocess, 21.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 persons, 21.3ms\n",
      "Speed: 3.1ms preprocess, 21.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 21.3ms\n",
      "Speed: 3.0ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 person, 20.7ms\n",
      "Speed: 3.6ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286.169617</td>\n",
       "      <td>236.163864</td>\n",
       "      <td>0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.082977</td>\n",
       "      <td>224.264435</td>\n",
       "      <td>0.978486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273.275116</td>\n",
       "      <td>224.945160</td>\n",
       "      <td>0.975879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321.056641</td>\n",
       "      <td>233.825043</td>\n",
       "      <td>0.864691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.760956</td>\n",
       "      <td>235.625854</td>\n",
       "      <td>0.805083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>267.109192</td>\n",
       "      <td>485.122833</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>375.120483</td>\n",
       "      <td>574.618591</td>\n",
       "      <td>0.996073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>233.417786</td>\n",
       "      <td>575.853760</td>\n",
       "      <td>0.997416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>392.337799</td>\n",
       "      <td>652.131104</td>\n",
       "      <td>0.968906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>210.495117</td>\n",
       "      <td>652.705994</td>\n",
       "      <td>0.976293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X           Y  Confidence\n",
       "0    286.169617  236.163864    0.994265\n",
       "1    300.082977  224.264435    0.978486\n",
       "2    273.275116  224.945160    0.975879\n",
       "3    321.056641  233.825043    0.864691\n",
       "4    256.760956  235.625854    0.805083\n",
       "..          ...         ...         ...\n",
       "335  267.109192  485.122833    0.999483\n",
       "336  375.120483  574.618591    0.996073\n",
       "337  233.417786  575.853760    0.997416\n",
       "338  392.337799  652.131104    0.968906\n",
       "339  210.495117  652.705994    0.976293\n",
       "\n",
       "[340 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for img in image_paths:\n",
    "    read_img = cv2.imread(img, 1)\n",
    "    img = cv2.resize(read_img, (600, 800))\n",
    "\n",
    "    # Predict keypoints on an image\n",
    "    results = model(img)\n",
    "    \n",
    "    # Access keypoints\n",
    "    keypoints = results[0].keypoints\n",
    "    tensor = keypoints.data.cpu().numpy()\n",
    "\n",
    "    # Calculate the confidence sum for each detected person\n",
    "    confidence_sums = tensor[:, :, 2].sum(axis=1)\n",
    "\n",
    "    # Find the index of the person with the highest confidence sum\n",
    "    best_person_idx = confidence_sums.argmax()\n",
    "\n",
    "    # Extract keypoints for the most confident person\n",
    "    best_person_keypoints = tensor[best_person_idx]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_img = pd.DataFrame(best_person_keypoints, columns=['X', 'Y', 'Confidence'])\n",
    "\n",
    "    all_dfs.append(df_img)\n",
    "\n",
    "# Combine all DataFrames into one if needed\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('yolov8n.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
